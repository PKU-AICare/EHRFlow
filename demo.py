import streamlit as st
from langchain_core.callbacks import CallbackManager

upload_dir = "datasets"
import openai
import os

from Tools.PythonTool import xiaoyaAnalyser
from langchain_community.callbacks import StreamlitCallbackHandler
from Utils.streamlitoutcallbackhandler import ChainStreamHandler
from GraceAgent import (
    GraceExecutor,
    GraceGPT,
    GracePlanner
)
from Tools import *
from langchain_openai import ChatOpenAI, OpenAI
from dotenv import load_dotenv, find_dotenv
from Tools.Interpreter import Interpreter

import warnings

warnings.filterwarnings("ignore")


def main():
    st.set_page_config(page_title="EHRFlow:æ‚¨çš„ä¸“å±åŒ»ç–—ç»“æ„åŒ–æ•°æ®åˆ†ææ™ºèƒ½åŠ©ç†", page_icon="ğŸ¤–", layout="wide")
    st.markdown(
        """
        <div style='text-align: center;'>
            <h1>EHRFlow</h1>
        </div>
        """,
        unsafe_allow_html=True,
    )
    st.markdown(
        """
        <div style='text-align: center;'>
            <h4>ğŸ¤–æ‚¨çš„ä¸“å±åŒ»ç–—ç»“æ„åŒ–æ•°æ®åˆ†ææ™ºèƒ½åŠ©ç†ğŸ¥°</h4>
        </div>
        """,
        unsafe_allow_html=True,
    )

    with st.sidebar:
        st.markdown("<h1 style='text-align:center;font-family:Georgia'>âš™ï¸ EHRFlow </h1>", unsafe_allow_html=True)
        st.markdown("""ä¸€ä¸ªç¨³å®šã€å¯æ§ã€å¯æ‰©å±•çš„è‡ªåŠ©å¼EHRæ•°æ®åˆ†æå¹³å°ã€‚è¯¥ç³»ç»Ÿæ—¨åœ¨æ·±å…¥è§£å†³åŒ»ç”Ÿåœ¨å®é™…å·¥ä½œä¸­é’ˆå¯¹ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰çš„æ•°æ®é—®ç­”å’Œæ•°æ®åˆ†æéœ€æ±‚ï¼Œ
                    èåˆäº†å¤§è¯­è¨€æ¨¡å‹Agentæ¡†æ¶å’Œæœ¬åœ°å·¥å…·ç±»ï¼Œä»¥å¢å¼ºåŒ»ç”Ÿä¸æ•°æ®åˆ†æå·¥å…·çš„äº¤äº’æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œä»è€Œæ¨åŠ¨åŒ»ç–—å†³ç­–çš„æ™ºèƒ½åŒ–å’Œä¸ªæ€§åŒ–åŒ»ç–—æœåŠ¡çš„å‘å±•ã€‚\n""")

        st.markdown("-------")
        st.markdown("<h1 style='text-align:center;font-family:Georgia'>ğŸŒŸFeatures</h1>", unsafe_allow_html=True)
        st.markdown(
            " - ğŸ§¾ è‡ªåŠ©å¼åˆ†æ - å¤§è¯­è¨€æ¨¡å‹æ·±åº¦èµ‹èƒ½ï¼Œæ™ºèƒ½é©±åŠ¨è‡ªåŠ©å¼åˆ†æã€‚")
        st.markdown(" - ğŸ¤‘ æ•°æ®é—®ç­”- EHR æ•°æ®å†…å®¹é«˜åº¦æŒæ§ï¼Œç©è½¬ EHR æ•°æ®")
        st.markdown(
            " - ğŸ§¾ æ™ºèƒ½å†³ç­– - æ·±å…¥åˆ†æå’ŒæŒ–æ˜åŒ»ç–—æ•°æ®ï¼Œé«˜æ•ˆå®ŒæˆåŒ»ç–—æ™ºèƒ½å†³ç­–")
        st.markdown("-------")
        st.markdown("<h1 style='text-align:center;font-family:Georgia'>ğŸ§¾ How to use?</h1>",
                    unsafe_allow_html=True)
        st.markdown(
            "1. Enter your OpenAI API key belowğŸ”‘")
        st.markdown("2. Upload Your EMR(csv) filesğŸ“„")
        st.markdown(
            "3. Ask a question about your datağŸ’¬")
        if os.path.exists(".env"):
            _ = load_dotenv(find_dotenv())
            openai.api_key = os.environ['OPENAI_API_KEY']
            openai.base_url = os.environ['OPENAI_API_BASE']
            st.success("API key loaded from .env", icon="ğŸš€")
        else:
            user_api_key = st.sidebar.text_input(
                label="#### Enter OpenAI API key ğŸ‘‡", placeholder="Paste your openAI API key, sk-", type="password",
                key="openai_api_key"
            )
            openai.api_key = user_api_key
            if user_api_key:
                st.sidebar.success("API key loaded", icon="ğŸš€")
        st.markdown('-------')
        # st.markdown('Peking University')

    uploaded_files = st.file_uploader("Upload your EHR data here ğŸ‘‡:", type="csv", accept_multiple_files=True)
    if not uploaded_files:
        st.stop()

    with st.spinner("Uploading documents... This may take a whileâ³"):
        for uploaded_file in uploaded_files:
            # è·å–ä¸Šä¼ æ–‡ä»¶çš„åç§°
            filename = os.path.join(upload_dir, uploaded_file.name)

            # å°†æ–‡ä»¶å†™å…¥åˆ°æœ¬åœ°æŒ‡å®šè·¯å¾„
            with open(filename, "wb") as f:
                f.write(uploaded_file.getvalue())

    print([uploaded_file.name for uploaded_file in uploaded_files])
    _init_mes = ("æ‚¨å¥½ï¼Œæˆ‘æ˜¯å°é›…ï¼Œä¸€ä¸ªæ“…é•¿å¤„ç†åŒ»ç–—ç»“æ„åŒ–æ•°æ®çš„æ™ºèƒ½åŠ©ç†ã€‚ğŸ¥³åœ¨æäº¤å®ŒEHRæ•°æ®ä¹‹åï¼Œæ‚¨å¯ä»¥å‘æˆ‘å°½æƒ…æå‡ºå…³äºEHR"
                 "åŒ»ç–—æ•°æ®çš„é—®é¢˜æˆ–è€…å¤„ç†è¦æ±‚ï¼Œæˆ‘ä¼šæ ¹æ®æ‚¨çš„éœ€æ±‚å¸®æ‚¨å¤„ç†æ•°æ®ï¼Œè¿”å›ç›¸åº”ç»“æœè¾…åŠ©æ‚¨æ›´å¥½åœ°è¿›è¡ŒåŒ»ç–—æ•°æ®åˆ†æã€‚ç°åœ¨æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ")

    if "messages" not in st.session_state.keys():
        st.session_state.messages = [{"role": "assistant", "content": _init_mes}]

    # Display or clear chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    def clear_chat_history():
        st.session_state.messages = [{"role": "assistant", "content": _init_mes}]

    st.sidebar.button('Clear Chat History', on_click=clear_chat_history)

    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

    st_callback = StreamlitCallbackHandler(st.container())
    interpreter = Interpreter()
    model = ChatOpenAI(model='gpt-4-turbo-preview', temperature=0, model_kwargs={"seed": 42})
    tools = [
        directory_inspection_tool,
        CSV_inspection_tool,
        finish_placeholder,
        xiaoyaAnalyser(
            model=model,
            prompt_path="./prompts/Tools",
            info_path="./Tools/xiaoya_info",
            interpreter=interpreter
        ).as_tool()
    ]
    dataset_folder_path = "./datasets"
    csv_files = [os.path.join(dataset_folder_path, uploaded_file.name) for uploaded_file in uploaded_files]
    planner = GracePlanner(model, tools, csv_files, stop=['<END_OF_PLAN>'])
    executor = GraceExecutor(
        llm=model,
        prompts_path="prompts/executor",
        tools=tools,
        work_dir='datasets',
        main_prompt_file='executor.json',
        files=csv_files,
        final_prompt_file='final_step.json',
        max_thought_steps=10,
    )
    agent = GraceGPT(planner=planner, executor=executor)

    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            response = agent.run(prompt, callbacks=[st_callback])
            # st.write_stream(chainStreamHandler.generate_tokens())
        message = {"role": "assistant", "content": response}
        st.session_state.messages.append(message)


if __name__ == "__main__":
    main()
