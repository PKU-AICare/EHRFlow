{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-09T12:57:46.133019Z",
     "start_time": "2024-03-09T12:57:45.532758Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     PatientID RecordTime Name  Value\n0            1  2020/1/31  Sex    1.0\n1            2   2020/2/5  Sex    1.0\n2            3  2020/1/23  Sex    0.0\n3            4   2020/2/1  Sex    1.0\n4            5   2020/2/2  Sex    0.0\n..         ...        ...  ...    ...\n370        371   2020/2/4  Sex    1.0\n371        372   2020/2/6  Sex    1.0\n372        373  2020/2/12  Sex    0.0\n373        374   2020/2/4  Sex    1.0\n374        375   2020/2/9  Sex    1.0\n\n[375 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PatientID</th>\n      <th>RecordTime</th>\n      <th>Name</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020/1/31</td>\n      <td>Sex</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2020/2/5</td>\n      <td>Sex</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2020/1/23</td>\n      <td>Sex</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2020/2/1</td>\n      <td>Sex</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2020/2/2</td>\n      <td>Sex</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>370</th>\n      <td>371</td>\n      <td>2020/2/4</td>\n      <td>Sex</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>371</th>\n      <td>372</td>\n      <td>2020/2/6</td>\n      <td>Sex</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>373</td>\n      <td>2020/2/12</td>\n      <td>Sex</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>373</th>\n      <td>374</td>\n      <td>2020/2/4</td>\n      <td>Sex</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>374</th>\n      <td>375</td>\n      <td>2020/2/9</td>\n      <td>Sex</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>375 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../datasets/raw_events_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T12:58:13.653936Z",
     "start_time": "2024-03-09T12:58:13.578879Z"
    }
   },
   "id": "58cc6ef49c5c3c6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "strs ={'input': '我想知道数据集中的男女比例信息', 'text': '关键概念: 数据集中的男女比例信息\\n概念拆解:\\n - 数据集文件\\n - 性别数据的标识方式\\n - 男女比例的计算方法\\n\\n反思:\\n - 已经使用ListDirectory动作探查\"./datasets\"文件夹，找到了数据集的具体文件。\\n - 还需要了解数据集的结构和性别数据的标识方式。\\n - 需要设计并执行AnalyseCSV动作来计算男女比例。\\n - 最终需要回答用户的问题关于数据集中的男女比例信息。\\n\\n思考:\\n  （1）首先需要了解数据集的结构，特别是性别数据的标识方式。\\n  （2）然后根据性别数据的标识方式，设计并执行AnalyseCSV动作来计算男女比例。\\n  （3）当前需要获得取值的子要素是数据集的结构和性别数据的标识方式。\\n\\n推理:\\n - 由于已经知道了\"./datasets\"文件夹中的数据集文件，下一步应该是使用InspectCSV动作探查这些文件，了解数据集的结构和性别数据的标识方式。\\n - 然后，根据性别数据的标识方式，可以设计并执行AnalyseCSV动作来计算男女比例。\\n\\n&计划&\\n1.对找到的数据集文件使用InspectCSV动作，了解数据集的结构和性别数据的标识方式。\\n2.根据性别数据的标识方式，设计并执行AnalyseCSV动作来计算男女比例。\\n3.鉴于以上步骤，请回答用户最初的问题：我想知道数据集中的男女比例信息。\\n<END_OF_PLAN>'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:23:56.597644Z",
     "start_time": "2024-03-11T13:23:56.592090Z"
    }
   },
   "id": "f3f3990e9e034412",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'关键概念: 数据集中的男女比例信息\\n概念拆解:\\n - 数据集文件\\n - 性别数据的标识方式\\n - 男女比例的计算方法\\n\\n反思:\\n - 已经使用ListDirectory动作探查\"./datasets\"文件夹，找到了数据集的具体文件。\\n - 还需要了解数据集的结构和性别数据的标识方式。\\n - 需要设计并执行AnalyseCSV动作来计算男女比例。\\n - 最终需要回答用户的问题关于数据集中的男女比例信息。\\n\\n思考:\\n  （1）首先需要了解数据集的结构，特别是性别数据的标识方式。\\n  （2）然后根据性别数据的标识方式，设计并执行AnalyseCSV动作来计算男女比例。\\n  （3）当前需要获得取值的子要素是数据集的结构和性别数据的标识方式。\\n\\n推理:\\n - 由于已经知道了\"./datasets\"文件夹中的数据集文件，下一步应该是使用InspectCSV动作探查这些文件，了解数据集的结构和性别数据的标识方式。\\n - 然后，根据性别数据的标识方式，可以设计并执行AnalyseCSV动作来计算男女比例。\\n\\n&计划&\\n1.对找到的数据集文件使用InspectCSV动作，了解数据集的结构和性别数据的标识方式。\\n2.根据性别数据的标识方式，设计并执行AnalyseCSV动作来计算男女比例。\\n3.鉴于以上步骤，请回答用户最初的问题：我想知道数据集中的男女比例信息。\\n<END_OF_PLAN>'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strs['text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:24:39.552158Z",
     "start_time": "2024-03-11T13:24:39.542040Z"
    }
   },
   "id": "20b41669289a4142",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Step:\n",
    "    value: str\n",
    "\n",
    "@dataclass\n",
    "class Plan:\n",
    "    steps: List[Step]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:32:06.030673Z",
     "start_time": "2024-03-11T13:32:06.026650Z"
    }
   },
   "id": "8414e997761c4d94",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PlanningOutputParser:\n",
    "    \"\"\"Planning output parser.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> Plan:\n",
    "        text = text[text.find(\"&计划&\"):]\n",
    "        step_texts = re.findall(r\"\\d+\\.(.*?)(?=\\d+\\.|$)\", text, flags=re.DOTALL)\n",
    "        steps = [Step(value=step.strip()) for step in step_texts]\n",
    "        return Plan(steps=steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:33:53.425106Z",
     "start_time": "2024-03-11T13:33:53.420168Z"
    }
   },
   "id": "6f2f6e6d90294bf6",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Plan(steps=[Step(value='对找到的数据集文件使用InspectCSV动作，了解数据集的结构和性别数据的标识方式。'), Step(value='根据性别数据的标识方式，设计并执行AnalyseCSV动作来计算男女比例。'), Step(value='鉴于以上步骤，请回答用户最初的问题：我想知道数据集中的男女比例信息。\\n<END_OF_PLAN>')])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PlanningOutputParser().parse(text=strs['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:33:53.861409Z",
     "start_time": "2024-03-11T13:33:53.838323Z"
    }
   },
   "id": "59fe2bce4af94d18",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import  OpenAIEmbeddings\n",
    "from langchain_text_splitters import  CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T13:46:05.988879Z",
     "start_time": "2024-03-12T13:46:04.442915Z"
    }
   },
   "id": "d38bd54325b78703",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "raw_documents = TextLoader(\"xiaoya_info/analysis.txt\").load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T13:47:05.313410Z",
     "start_time": "2024-03-12T13:47:05.288313Z"
    }
   },
   "id": "e662b51f20fa6f7c",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T09:01:13.277385Z",
     "start_time": "2024-03-13T09:01:13.270919Z"
    }
   },
   "id": "67d8b5f67c75383b",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "info_path = \"xiaoya_info\"\n",
    "info = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T09:05:56.005545Z",
     "start_time": "2024-03-13T09:05:55.999766Z"
    }
   },
   "id": "29a350bda3dc3f37",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_names = os.listdir(info_path)\n",
    "for file_name in file_names:\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        key = file_name.rstrip(\".txt\")\n",
    "        with open(os.path.join(info_path, file_name), 'r') as file:\n",
    "            content = file.read()\n",
    "            info[key] = content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T09:05:56.382248Z",
     "start_time": "2024-03-13T09:05:56.258833Z"
    }
   },
   "id": "a7688973e1d0107d",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'数据预处理': \"`DataHandler`类是一个用于处理和准备用户上传数据的工具，它支持数据表格的合并、数据格式的标准化、特征提取、数据集分割、数据归一化以及数据的前向填充。751\\n`DataHandler`类适用于需要对医疗数据进行预处理的场景，例如在机器学习项目中准备数据集。它可以帮助用户将原始数据转换为适合模型训练的格式，并将其分割为适当的训练、验证和测试集。\\n\\n### 类名\\n- `DataHandler`\\n\\n### 构造函数 (`__init__`)\\n- **参数**:\\n  - `labtest_data`: 一个`pd.DataFrame`，包含实验室测试数据。\\n  - `events_data`: 一个`pd.DataFrame`，包含事件数据。\\n  - `target_data`: 一个`pd.DataFrame`，包含目标数据。\\n  - `data_path`: 一个`Path`对象，表示保存处理后数据的路径，默认为`Path('./datasets')`。\\n\\n### 方法\\n- `format_dataframe`\\n  - **功能**: 根据指定的格式标准化数据。\\n  - **参数**:\\n    - `format`: 一个字符串，指定数据的格式，必须是`['labtest', 'events', 'target']`之一。\\n  - **返回值**: 标准化后的`pd.DataFrame`。\\n\\n- `merge_dataframes`\\n  - **功能**: 合并已标准化的数据表格。\\n  - **返回值**: 合并后的`pd.DataFrame`。\\n\\n- `format_and_merge_dataframes`\\n  - **功能**: 格式化并合并数据表格。\\n  - **返回值**: 合并后的`pd.DataFrame`。\\n\\n- `save_processed_data`\\n  - **功能**: 将处理后的数据保存到指定目录。\\n  - **无参数**。\\n\\n- `extract_features`\\n  - **功能**: 从原始数据表格中提取特征。\\n  - **参数**:\\n    - `format`: 一个字符串，指定数据的格式，必须是`['labtest', 'events', 'target']`之一。\\n  - **返回值**: 一个字典，包含提取的特征。\\n\\n- `list_all_features`\\n  - **功能**: 列出所有从原始数据表格中提取的特征。\\n  - **返回值**: 一个字典，包含所有格式的数据表格的特征。\\n\\n- `analyze_dataset`\\n  - **功能**: 分析数据集并返回特征的统计信息。\\n  - **返回值**: 一个字典，包含特征的详细信息和统计数据。\\n\\n- `split_dataset`\\n  - **功能**: 将数据集分割为训练集、验证集和测试集。\\n  - **参数**:\\n    - `train_size`: 一个整数，表示训练集的大小百分比。\\n    - `val_size`: 一个整数，表示验证集的大小百分比。\\n    - `test_size`: 一个整数，表示测试集的大小百分比。\\n    - `seed`: 一个整数，用于随机分割的种子。\\n  - **无返回值**。\\n\\n- `save_record_time`\\n  - **功能**: 保存每位患者的记录时间。\\n  - **无参数**。\\n\\n- `normalize_dataset`\\n  - **功能**: 归一化数据集中的特征。\\n  - **参数**:\\n    - `normalize_features`: 一个字符串列表，包含需要归一化的特征名称。\\n  - **无返回值**。\\n\\n- `forward_fill_dataset`\\n  - **功能**: 对数据集进行前向填充。\\n  - **参数**:\\n    - `demographic_features`: 一个字符串列表，包含人口统计特征。\\n    - `labtest_features`: 一个字符串列表，包含实验室测试特征。\\n  - **无返回值**。\\n\\n- `execute`\\n  - **功能**: 执行整个预处理流程，包括格式化和合并数据表格、分割数据集、归一化数据集和前向填充数据集。\\n  - **参数**:\\n    - `train_size`, `val_size`, `test_size`, `seed`: 与`split_dataset`方法相同的参数。\\n  - **无返回值**。\\n\\n\\n\",\n '数据可视化': \"这四个函数用于生成和保存数据集的分布直方图、特征重要性条形图、风险曲线图和患者嵌入散点图，以便于数据分析和可视化。712\\n\\n### 函数：`plot_vis_dataset`\\n- **目的**: 该函数用于绘制数据集中各个特征的分布情况。\\n- **参数**:\\n  - `data`: 一个列表，包含了多个患者数据的特征及其值。\\n  - `save_path`: 一个字符串，指定保存生成的图表的目录路径。\\n- **行为**:\\n  - 遍历`data`列表中的每个特征，为每个特征创建一个直方图，并将其保存到`save_path`指定的目录中。\\n\\n### 函数：`plot_feature_importance`\\n- **目的**: 该函数用于绘制特征重要性的条形图。\\n- **参数**:\\n  - `data`: 一个列表，包含了多个患者数据的特征及其重要性值。\\n  - `save_path`: 一个字符串，指定保存生成的图表的目录路径。\\n  - `feature_num`: 一个整数，表示要在条形图中显示的特征数量，默认为10。\\n  - `file_name`: 一个字符串，用于指定保存的图表文件名，默认为'feature_importance'。\\n- **行为**:\\n  - 计算并排序特征的重要性，选择最重要的`feature_num`个特征，并将它们绘制成条形图，然后保存到`save_path`指定的目录中。\\n\\n### 函数：`plot_risk_curve`\\n- **目的**: 该函数用于绘制患者的风险曲线以及其他健康指标。\\n- **参数**:\\n  - `data`: 一个字典，包含了多个患者数据的特征及其值。\\n  - `time`: 一个列表，表示时间点。\\n  - `time_risk`: 一个列表，表示对应时间点的风险指数。\\n  - `save_path`: 一个字符串，指定保存生成的图表的目录路径。\\n  - `feature_num`: 一个整数，表示要绘制的健康指标数量，默认为3。\\n  - `file_name`: 一个字符串，用于指定保存的图表文件名，默认为'risk_curve'。\\n- **行为**:\\n  - 为每个特征创建一个图表，将风险指数和其他健康指标绘制在同一图表中，然后保存到`save_path`指定的目录中。\\n\\n### 函数：`plot_patient_embedding`\\n- **目的**: 该函数用于在2D或3D空间中绘制患者嵌入的散点图。\\n- **参数**:\\n  - `data`: 一个列表，包含了多个患者的嵌入数据。\\n  - `save_path`: 一个字符串，指定保存生成的图表的目录路径。\\n  - `dimension`: 一个整数，表示嵌入空间的维度，必须是2或3。\\n  - `file_name`: 一个字符串，用于指定保存的图表文件名，默认为'patient_embedding_reduction'。\\n- **行为**:\\n  - 根据`dimension`参数的值，为每个患者的嵌入数据创建一个散点图，并将其保存到`save_path`指定的目录中。\\n\",\n '数据分析': '这个`DataAnalyzer`类是一个用于分析医疗数据并提供多种分析结果的工具。888\\n`DataAnalyzer`类适用于医疗数据分析场景，特别是在处理电子病历记录（EMR）时，可以用于识别患者的风险、提供个性化的医疗建议、减少数据维度以便可视化和分析，以及找到具有相似病情的患者群体。\\n\\n### 类名\\n- `DataAnalyzer`\\n\\n### 构造函数 (`__init__`)\\n- **参数**:\\n  - `config`: 一个字典（`Dict`），包含数据管道的配置信息。\\n  - `model_path`: 一个字符串（`str`），表示模型保存的路径。\\n\\n### 方法\\n- `adaptive_feature_importance`\\n  - **功能**: 计算并返回患者的自适应特征重要性。\\n  - **参数**:\\n    - `df`: 一个`pd.DataFrame`，代表患者的原始数据。\\n    - `x`: 一个列表（`List`），形状为`[batch_size, time_step, feature_dim]`，代表患者的输入数据。\\n    - `patient_index`: 一个可选的整数（`Optional[int]`），代表数据帧中患者的索引。\\n    - `patient_id`: 一个可选的整数（`Optional[int]`），代表数据帧中记录的患者ID。`patient_index`和`patient_id`只能选择其一。\\n  - **返回值**: 一个字典，包含自适应特征重要性的详细信息。\\n\\n- `feature_importance`\\n  - **功能**: 计算并返回患者的特征重要性。\\n  - **参数**: 与`adaptive_feature_importance`方法相同。\\n  - **返回值**: 一个列表，包含特征重要性的详细信息。\\n\\n- `risk_curve`\\n  - **功能**: 计算并返回患者的风险曲线，以及每次就诊时患者的特征重要性。\\n  - **参数**:\\n    - 与`adaptive_feature_importance`方法相同，额外包含`mean`和`std`字典，以及可选的`mask`列表。\\n  - **返回值**: 包含特征详细信息、就诊日期和患者每次就诊的死亡风险的列表。\\n\\n- `ai_advice`\\n  - **功能**: 根据AI系统的分析，返回给患者的建议。\\n  - **参数**:\\n    - 与`adaptive_feature_importance`方法相同，额外包含`mean`和`std`字典，以及`time_index`整数。\\n  - **返回值**: 一个列表，包含AI系统建议的详细信息。\\n\\n- `data_dimension_reduction`\\n  - **功能**: 通过降维方法（如PCA或TSNE）减少患者数据的维度。\\n  - **参数**:\\n    - `df`: 一个`pd.DataFrame`，代表患者的原始数据。\\n    - `x`: 一个列表（`List`），形状为`[batch_size, time_step, feature_dim]`，代表患者的输入数据。\\n    - `mean_age`和`std_age`: 可选的浮点数（`Optional[float]`），代表患者的平均年龄和标准差。\\n    - `method`: 一个字符串（`str`），表示降维方法，默认为\"PCA\"。\\n    - `dimension`: 一个整数（`int`），表示降维后的目标维度，默认为2。\\n    - `target`: 一个字符串（`str`），表示模型的目标，默认为\"outcome\"。\\n  - **返回值**: 一个列表，包含降维后患者数据的详细信息。\\n\\n- `similar_patients`\\n  - **功能**: 找到与给定患者相似的患者信息。\\n  - **参数**:\\n    - `x_df`: 一个`pd.DataFrame`，代表患者的原始数据。\\n    - `x`: 一个列表（`List`），形状为`[batch_size, time_step, feature_dim]`，代表患者的输入数据。\\n    - `p_df`: 一个`pd.DataFrame`，代表相似患者的原始数据。\\n    - `patients`: 一个列表（`List`），形状与`x`相同，代表相似患者的输入数据。\\n    - `mean`和`std`: 与前面方法相同的字典。\\n    - `patient_index`和`patient_id`: 与前面方法相同的可选整数。\\n    - `n_clu`: 一个整数（`int`），表示聚类的数量，默认为10。\\n    - `topk`: 一个整数（`int`），表示返回的相似患者数量，默认为6。\\n  - **返回值**: 一个列表，包含相似患者信息的详细信息。\\n\\n'}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T09:05:57.020905Z",
     "start_time": "2024-03-13T09:05:56.910169Z"
    }
   },
   "id": "977759d3ab449f8",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['数据预处理.txt', '数据可视化.txt', '数据分析.txt']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T09:03:16.200013Z",
     "start_time": "2024-03-13T09:03:16.179141Z"
    }
   },
   "id": "64cf535dbf868022",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2fe3a9179a5684a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_experimental.plan_and_execute.schema import Plan, PlanOutputParser, Step"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T13:43:41.539958Z",
     "start_time": "2024-03-13T13:43:41.510437Z"
    }
   },
   "id": "e48b1d31063281ae",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "steps=[Step(value='使用InspectCSV动作，查看\"./datasets\"路径下每个csv文件的基本结构和前几行数据，以评估数据预处理的需求。'), Step(value='使用xiaoya包对\"./datasets\"路径下的每个csv文件进行数据预处理，包括数据表格的合并、数据格式的标准化、特征提取等。'), Step(value='根据用户的具体需求，决定是否继续使用xiaoya包对预处理后的数据进行数据分析和数据可视化。'), Step(value='如果进行数据分析，使用xiaoya包识别患者的风险、提供个性化的医疗建议、减少数据维度以便可视化和分析，以及找到具有相似病情的患者群体。'), Step(value='如果进行数据可视化，使用xiaoya包生成和保存数据集的分布直方图、特征重要性条形图、风险曲线图和患者嵌入散点图。'), Step(value='鉴于以上步骤，请回答用户最初的问题：请帮我处理一下数据集。\\n<END_OF_PLAN>')]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T13:43:42.420735Z",
     "start_time": "2024-03-13T13:43:42.280383Z"
    }
   },
   "id": "e9efecfe8f7b1084",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plan = Plan(steps=[Step(value='使用ListDirectory动作列出\"./datasets\"文件夹中的所有文件，以确定可用的csv数据集。'), Step(value='对每个csv文件使用InspectCSV动作进行内容探查，了解其数据结构和内容。'), Step(value='使用xiaoya包对所有csv文件进行数据预处理，确保数据质量。'), Step(value='根据用户的具体需求，决定是否对数据进行分析和可视化，如果需要，则使用xiaoya包进行相应的操作。'), Step(value='鉴于以上步骤，请回答用户最初的问题。\\n<END_OF_PLAN>')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T13:58:46.619719Z",
     "start_time": "2024-03-13T13:58:46.593213Z"
    }
   },
   "id": "7af7b87bd496d023",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step_values_set = [step.value for step in plan.steps]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:04:36.471693Z",
     "start_time": "2024-03-13T14:04:36.454577Z"
    }
   },
   "id": "7ade673334efb062",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'使用ListDirectory动作列出\"./datasets\"文件夹中的所有文件，以确定可用的csv数据集。',\n '使用xiaoya包对所有csv文件进行数据预处理，确保数据质量。',\n '对每个csv文件使用InspectCSV动作进行内容探查，了解其数据结构和内容。',\n '根据用户的具体需求，决定是否对数据进行分析和可视化，如果需要，则使用xiaoya包进行相应的操作。',\n '鉴于以上步骤，请回答用户最初的问题。\\n<END_OF_PLAN>'}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(step_values_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:04:50.402346Z",
     "start_time": "2024-03-13T14:04:50.392118Z"
    }
   },
   "id": "26f449490187e1d3",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Step(value='使用ListDirectory动作列出\"./datasets\"文件夹中的所有文件，以确定可用的csv数据集。'),\n Step(value='对每个csv文件使用InspectCSV动作进行内容探查，了解其数据结构和内容。'),\n Step(value='使用xiaoya包对所有csv文件进行数据预处理，确保数据质量。'),\n Step(value='根据用户的具体需求，决定是否对数据进行分析和可视化，如果需要，则使用xiaoya包进行相应的操作。'),\n Step(value='鉴于以上步骤，请回答用户最初的问题。\\n<END_OF_PLAN>')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.steps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T13:58:51.375315Z",
     "start_time": "2024-03-13T13:58:51.359311Z"
    }
   },
   "id": "5899ee2f54de5456",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Plan(steps=[Step(value='使用ListDirectory动作列出\"./datasets\"文件夹中的所有文件，以确定可用的csv数据集。'), Step(value='对每个csv文件使用InspectCSV动作进行内容探查，了解其数据结构和内容。'), Step(value='使用xiaoya包对所有csv文件进行数据预处理，确保数据质量。'), Step(value='根据用户的具体需求，决定是否对数据进行分析和可视化，如果需要，则使用xiaoya包进行相应的操作。'), Step(value='鉴于以上步骤，请回答用户最初的问题。\\n<END_OF_PLAN>')])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Plan(steps = plan.steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:01:53.556817Z",
     "start_time": "2024-03-13T14:01:53.366419Z"
    }
   },
   "id": "6ebf18948b78d889",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plan = Plan(steps=[Step(value='使用xiaoya包的一键操作功能对\"./datasets\"文件夹中找到的所有csv文件(raw_target_data.csv, raw_events_data.csv, raw_labtest_data.csv)进行数据预处理。'), Step(value='完成数据预处理后，确认预处理是否成功完成。\\n<END_OF_PLAN>')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:31:20.590935Z",
     "start_time": "2024-03-14T06:31:20.569659Z"
    }
   },
   "id": "a9c3f41894325916",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Step(value='使用xiaoya包的一键操作功能对\"./datasets\"文件夹中找到的所有csv文件(raw_target_data.csv, raw_events_data.csv, raw_labtest_data.csv)进行数据预处理。'),\n Step(value='完成数据预处理后，确认预处理是否成功完成。\\n<END_OF_PLAN>')]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.steps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:54:17.074935Z",
     "start_time": "2024-03-14T06:54:17.067709Z"
    }
   },
   "id": "9bee8fc2e238f928",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Plan(steps=[Step(value='使用xiaoya包的一键操作功能对\"./datasets\"文件夹中找到的所有csv文件(raw_target_data.csv, raw_events_data.csv, raw_labtest_data.csv)进行数据预处理。'), Step(value='完成数据预处理后，确认预处理是否成功完成。\\n<END_OF_PLAN>')])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:31:23.313790Z",
     "start_time": "2024-03-14T06:31:23.309709Z"
    }
   },
   "id": "516a808b77a9bd7c",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mTools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/Downloads/GraceGPT/Tools/Tools.py:7\u001B[0m\n\u001B[1;32m      5\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StructuredTool\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mFileTools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m list_files_in_directory\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mWriterTool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m write\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mCSVTool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_first_n_rows, get_column_names\n",
      "\u001B[0;31mImportError\u001B[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from Tools import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T11:46:13.935584Z",
     "start_time": "2024-03-14T11:46:13.825699Z"
    }
   },
   "id": "45cd3d0a942cda68",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T08:11:19.246848Z",
     "start_time": "2024-03-14T08:11:19.226492Z"
    }
   },
   "id": "160300bb9aa2f50",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T08:11:28.650461Z",
     "start_time": "2024-03-14T08:11:28.640140Z"
    }
   },
   "id": "56941b1a9a8a82ed",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8e16cc0c64cad29b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
